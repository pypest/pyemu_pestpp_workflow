{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a PEST interface from MODFLOW6 using the `PstFrom` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PstFrom` class is a generalization of the prototype `PstFromFlopy` class. The generalization in `PstFrom` means users need to explicitly define what files are to be parameterized and what files contain model outputs to treat as observations.  Two primary types of files are supported:  arrays and lists.  Array files contain a data type (usually floating points) while list files will have a few columns that contain index information and then columns of floating point values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n",
    "import pyemu\n",
    "import flopy\n",
    "import sys\n",
    "# plt.rcParams['xtick.labelsize'] = 'large'\n",
    "# plt.rcParams['ytick.labelsize'] = 'large'\n",
    "plt.rcParams['font.size'] = 14\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'pestpp_exes')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'mf_exes')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View existing model\n",
    "An existing MODFLOW6 model is in the directory `freyberg_mf6`.  Lets check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_model_ws = os.path.join('model_files_lowres')\n",
    "os.listdir(org_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all the input array and list data for this model have been written \"externally\" - this is key to using the `PstFrom` class. \n",
    "\n",
    "Let's quickly viz the model top just to remind us of what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_arr = np.loadtxt(os.path.join(org_model_ws,\"freyberg6.dis_idomain_layer1.txt\"))\n",
    "top_arr = np.loadtxt(os.path.join(org_model_ws,\"freyberg6.dis_top.txt\")).reshape(id_arr.shape)\n",
    "top_arr[id_arr==0] = np.nan\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "im = plt.imshow(top_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"mf6\",cwd=org_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy to preserve original model\n",
    "Now let's copy those files to a temporary location just to make sure we don't goof up those original files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_model_ws = \"temp_pst_from\"\n",
    "if os.path.exists(tmp_model_ws):\n",
    "    shutil.rmtree(tmp_model_ws)\n",
    "shutil.copytree(org_model_ws,tmp_model_ws)\n",
    "os.listdir(tmp_model_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct PEST interface e.g.\n",
    "### Collect/define spatial information for model\n",
    "Now we need just a tiny bit of info about the spatial discretization of the model - this is needed to work out separation distances between parameters for build a geostatistical prior covariance matrix later.\n",
    "\n",
    "Here we will load the flopy sim and model instance just to help us define some quantities later - flopy is not required to use the `PstFrom` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_model_ws)\n",
    "m = sim.get_model(\"freyberg6\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the simple `SpatialReference` pyemu implements to help us spatially locate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr = pyemu.helpers.SpatialReference(delr=m.dis.delr.array, delc=m.dis.delc.array)\n",
    "# sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "#         os.path.join(tmp_model_ws, \"freyberg6.nam\"),\n",
    "#         delr=m.dis.delr.array, delc=m.dis.delc.array)\n",
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start `PstFrom()` build\n",
    "Now we can instantiate a `PstFrom` class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template_ws = \"freyberg6_template\"\n",
    "pf = pyemu.utils.PstFrom(\n",
    "    original_d=tmp_model_ws,  # where to find reference model\n",
    "    new_d=template_ws,  # where to build PEST\n",
    "    remove_existing=True,  # Stomp in new_d, if it exists\n",
    "    longnames=True,  # use PESTPP long paramter and observation names (handy storing metadata)\n",
    "    spatial_reference=sr,  # model spatial reference info\n",
    "    zero_based=False,  # model uses zero-based references\n",
    "    start_datetime=\"1-1-2018\"\n",
    ")  # model start time reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Observations\n",
    "\n",
    "So now that we have a `PstFrom` instance, but its just an empty container at this point, so we need to add some PEST interface \"observations\" and \"parameters\".  \n",
    "#### Water level observations/outputs\n",
    "Let's start with observations using MODFLOW6 head.  These are stored in `heads.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(tmp_model_ws,\"heads.csv\"),index_col=0)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main entry point for adding observations is (surprise) `PstFrom.add_observations()`.  This method works on the list-type observation output file.  We need to tell it what column is the index column (can be string if there is a header or int if no header) and then what columns contain quantities we want to monitor (e.g. \"observe\") in the control file - in this case we want to monitor all columns except the index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hds_df = pf.add_observations(\n",
    "    \"heads.csv\",  # model output file to use \n",
    "    insfile=\"heads.csv.ins\",  # optional, define name of PEST instruction file\n",
    "    index_cols=\"time\",  # column used to index observation/outputs\n",
    "    use_cols=list(df.columns.values),  # columns to setup observations for (can be multiple)\n",
    "    prefix=\"hds\",  # observation name prefix\n",
    ")\n",
    "display(hds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it returned a dataframe with lots of useful info: the observation names that were formed (`obsnme`), the values that were read from `heads.csv` (`obsval`) and also some generic weights and group names.  At this point, no control file has been created, we have simply prepared to add this observations to the control file later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[f for f in os.listdir(template_ws) if f.endswith(\".ins\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!  We also have a PEST-style instruction file for those obs.\n",
    "#### Stream flow observations/outputs\n",
    "Now lets do the same for SFR observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(tmp_model_ws, \"sfr.csv\"), index_col=0)\n",
    "sfr_df = pf.add_observations(\n",
    "    \"sfr.csv\", \n",
    "    insfile=\"sfr.csv.ins\", \n",
    "    index_cols=\"time\", \n",
    "    use_cols=list(df.columns.values)\n",
    ")\n",
    "sfr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet as!  Now that we have some observations, let's add parameters!\n",
    "\n",
    "### Add Parameters\n",
    "\n",
    "In the `PstFrom` realm, parameters can be setup as `direct` parameter values the relate to model input files, or as `multipliers` against existing array and list files.  Multipliers are handy because it lets us preserve the existing model inputs and treat them as the mean of the prior parameter distribution. It also let's us use mixtures of spatial and temporal scales in the parameters to account for varying scale of uncertainty. \n",
    "\n",
    "#### Geostats\n",
    "Since we are all sophisticated and recognize the importance of expressing spatial and temporal uncertainty (e.g. heterogeneity) in the model inputs (and the corresponding spatial correlation in those uncertain inputs), let's use geostatistics to express uncertainty.  To do that we need to define \"geostatistical structures\".  As we will see, defining parameter correlation is optional and only matters for the prior parameter covariance matrix and prior parameter ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=1000)\n",
    "grid_gs = pyemu.geostats.GeoStruct(variograms=v, transform='log')\n",
    "temporal_gs = pyemu.geostats.GeoStruct(variograms=pyemu.geostats.ExpVario(contribution=1.0,a=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "grid_gs.plot(ax=ax)\n",
    "print(\"spatial variogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "temporal_gs.plot(ax=ax)\n",
    "ax.set_xlabel(\"distance (days)\")\n",
    "\"temporal variogram (x axis in days)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial parameters e.g.\n",
    "Now let's get the idomain array to use as a zone array - this keeps us from setting up parameters in inactive model cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ib = m.dis.idomain[0].array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's setup parameters for **static properties** - HK, VK, SS, SY.  Do that, we need to find all the external array files that contain these static arrays.  Let's do **just HK** slowly so as to explain what is happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hk_arr_files = [f for f in os.listdir(tmp_model_ws) if \"npf_k_\" in f and f.endswith(\".txt\")]\n",
    "hk_arr_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So those are the existing model input arrays for HK.  Notice we found the files in the temporary model workspace - `PstFrom` will copy all those files to the new model workspace for us in a bit...\n",
    "\n",
    "Let's setup **grid-scale multiplier** parameter for HK in layer 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pf.add_parameters(\n",
    "    filenames=\"freyberg6.npf_k_layer1.txt\",  # filename to setup parameters for\n",
    "    par_type=\"grid\",  # type of paramter (resoloution of paramterisation, e.g. grid, pilotpoint, zone, constant)\n",
    "    par_name_base=\"hk_layer_1\",  # base names for constructed parameters\n",
    "    pargp=\"hk_layer_1\",  # PEST group for all paramters constructed from this file(s)\n",
    "    zone_array=ib,  # array for zones (also used to \"select\" area for setting up other parameters)\n",
    "    upper_bound=10.,  # PEST upper paramter bound\n",
    "    lower_bound=0.1,  # PEST lower parameter bound\n",
    "    ult_ubound=100,  # Maximum allowed values for resultant native model parameter (after multipliers applied) \n",
    "    ult_lbound=0.01  # Minimum allowed values for resultant native model parameter (after multipliers applied) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What just happened there?  Well, we told our `PstFrom` instance to setup a set of **grid-scale multiplier** parameters (`par_type=\"grid\"`) for the array file \"freyberg6.npf_k_layer1.txt\". We told it to prefix the parameter names with \"hk_layer_1\" and also to make the parameter group \"hk_layer_1\" (`pargp=\"hk_layer_1\"`).  When specified two sets of bound information:  `upper_bound` and `lower_bound` are the standard control file bounds, while `ult_ubound` and `ult_lbound` are bounds that are applied at runtime to the resulting (multiplied out) model input array - since we are using multipliers (and potentially, sets of multipliers - stay tuned), it is important to make sure we keep the resulting model input arrays within the range of realistic values.\n",
    "\n",
    "If you inspect the contents of the working directory, we will see a new template file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(template_ws,\"hk_layer_1_inst0_grid.csv.tpl\"),'r') as f:\n",
    "    for _ in range(2):\n",
    "        print(f.readline().strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So those might look like pretty redic parameter names, but they contain heaps of metadata to help you post process things later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build PEST control file?\n",
    "At this point, we have some parameters and some observations, so we can create a control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pst = pf.build_pst()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh snap! we did it!  thanks for playing...\n",
    "\n",
    "Well, there is a little more to the story.  Like how do we run this thing? Lucky for you, `PstFrom` writes a forward run script for you! Say Wat?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[f for f in os.listdir(template_ws) if f.endswith(\".py\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = [print(line.rstrip()) for line in open(os.path.join(template_ws,\"forward_run.py\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! We have everything we need...**except a command to run the model!** Doh!  \n",
    "\n",
    "Let's add that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only execute this block once!\n",
    "pf.mod_sys_cmds.append(\"mf6\")\n",
    "pst = pf.build_pst()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = [print(line.rstrip()) for line in open(os.path.join(template_ws,\"forward_run.py\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!  See the last line in `main()`?  \n",
    "## Generating geostatistical prior covariance matrices and ensembles\n",
    "\n",
    "So that's nice, but how do we include spatial correlation in these parameters?  It simple: just pass the `geostruct` arg to `PstFrom.add_parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pf.add_parameters(\n",
    "    filenames=\"freyberg6.npf_k_layer3.txt\",\n",
    "    par_type=\"grid\",\n",
    "    par_name_base=\"hk_layer_3\",\n",
    "    pargp=\"hk_layer_3\",\n",
    "    zone_array=ib,\n",
    "    upper_bound=10.,\n",
    "    lower_bound=0.1,\n",
    "    ult_ubound=100,\n",
    "    ult_lbound=0.01,\n",
    "    geostruct=grid_gs  # <-------------------------------- ADDING GEOSTRUCT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's also check out the super awesome prior parameter covariance matrix and prior parameter ensemble helpers in `PstFrom`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pst = pf.build_pst()\n",
    "cov = pf.build_prior()\n",
    "x = cov.x.copy()\n",
    "x[x==0.0] = np.NaN\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "im = plt.imshow(x, interpolation='none')\n",
    "plt.gca().set_facecolor('k')\n",
    "# cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ix = x.shape[0]\n",
    "zoom = int(ix*(700/1412))\n",
    "im = plt.imshow(x[zoom:,zoom:], interpolation='none')\n",
    "plt.gca().set_facecolor('k')\n",
    "fig.savefig('kcov.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da-um!  that's sweet ez!  We can see the **first block of HK parameters in the upper left as \"uncorrelated\"** (diagonal only) entries, then the **second block of HK parameters (lower right) that are spatially correlated**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List/tabular file parameterization\n",
    "\n",
    "Let's add parameters for well extraction rates (always uncertain, rarely estimated!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wel_files = [f for f in os.listdir(tmp_model_ws) if \"wel_stress_period\" in f and f.endswith(\".txt\")]\n",
    "wel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(tmp_model_ws,wel_files[0]),header=None, sep='\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal parameters\n",
    "There are several ways to approach wel file parameterization.  \n",
    "\n",
    "One way is to add a **constant multiplier parameter** for each stress period (that is, one scaling parameter that is applied all active wells for each stress period).  \n",
    "\n",
    "Let's see how that looks, but first one important point:  If you use the same parameter group name (`pargp`) and same geostruct, the `PstFrom` will treat parameters setup across different calls to `add_parameters()` as correlated.  In this case, **we want to express temporal correlation in the well multiplier pars**, so we use the **same parameter group names**, specify the `datetime` and `geostruct` args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build up a container of stress period start datetimes - this will\n",
    "# be used to specify the datetime of each multipler parameter\n",
    "dts = pd.to_datetime(pf.start_datetime) + pd.to_timedelta(np.cumsum(sim.tdis.perioddata.array[\"perlen\"]),unit='d')\n",
    "\n",
    "for wel_file in wel_files:\n",
    "    # get the stress period number from the file name\n",
    "    kper = int(wel_file.split('.')[1].split('_')[-1]) - 1  \n",
    "    pf.add_parameters(\n",
    "        filenames=wel_file,  # An independent constant parameter for each well file\n",
    "        par_type=\"constant\",\n",
    "        par_name_base=\"wel_cn\",\n",
    "        pargp=\"wel_cn\", \n",
    "        upper_bound = 1.5, \n",
    "        lower_bound=0.5,\n",
    "        datetime=dts[kper],  # time asociated with file (for tempoaral covariance)\n",
    "        geostruct=temporal_gs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pst = pf.build_pst()\n",
    "cov = pf.build_prior(fmt=\"none\") # skip saving to a file...\n",
    "x = cov.x.copy()\n",
    "x[x==0] = np.NaN\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "im = plt.imshow(x, interpolation='none')\n",
    "plt.gca().set_facecolor('k')\n",
    "cb = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the little offset in the lower right?  there are a few parameters there in a small block - those are our constant-in-space but correlated in time wel rate parameters! snap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "im = ax.imshow(x[ix:,ix:], interpolation='none')\n",
    "ax.set_facecolor('k')\n",
    "cn = plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial pars on same model files\n",
    "To compliment those stress period level constant multipliers, lets add a **set of multipliers**, one for each pumping well, that is **broadcast across all stress periods** (and let's add spatial correlation for these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pf.add_parameters(\n",
    "    filenames=wel_files,  # one set of parameters across all files\n",
    "    par_type=\"grid\",\n",
    "    par_name_base=\"wel_gr\",\n",
    "    pargp=\"wel_gr\", \n",
    "    upper_bound = 1.5, \n",
    "    lower_bound=0.5,\n",
    "    geostruct=grid_gs  # spatial covariance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pst = pf.build_pst()\n",
    "cov = pf.build_prior(fmt=\"none\")\n",
    "x = cov.x.copy()\n",
    "x[x==0] = np.NaN\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "im = plt.imshow(x, interpolation='none')\n",
    "plt.gca().set_facecolor('k')\n",
    "cb = plt.colorbar(im)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,12))\n",
    "im = ax.imshow(x[ix:,ix:], interpolation='none')\n",
    "ax.set_facecolor('k')\n",
    "cn = plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a prior parameter ensemble\n",
    "\n",
    "This is crazy easy - using the previous defined correlation structures, we can draw from the block diagonal covariance matrix (and use spectral simulation for the grid-scale parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=100,use_specsim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pe.to_csv(os.path.join(template_ws,\"prior.csv\"))\n",
    "display(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(pe.loc[:,pst.adj_par_names[:5]])\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "h = pe.loc[:,pst.adj_par_names[0]]._df.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "\n",
    "# Industrial strength control file setup\n",
    "\n",
    "Let's kick it up a notch!\n",
    "This functionality mimics the demonstration the `PstFrom` manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the mf6 model with flopy to get the spatial reference\n",
    "sim = flopy.mf6.MFSimulation.load(sim_ws=tmp_model_ws)\n",
    "m = sim.get_model(\"freyberg6\")\n",
    "\n",
    "# work out the spatial rediscretization factor\n",
    "redis_fac = m.dis.nrow.data / 40\n",
    "\n",
    "# where the pest interface will be constructed\n",
    "template_ws = \"freyberg6_template\"\n",
    "\n",
    "\n",
    "# instantiate PstFrom object\n",
    "pf = pyemu.utils.PstFrom(\n",
    "    original_d=tmp_model_ws, \n",
    "    new_d=template_ws,\n",
    "    remove_existing=True,\n",
    "    longnames=True, \n",
    "    spatial_reference=m.modelgrid,\n",
    "    zero_based=False,\n",
    "    start_datetime=\"1-1-2018\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "add observations from the sfr and heads observation output files...but instead using the \"time\" in these files,  let's use datetime instead. To do this, we need some trickeration\n",
    "\n",
    "First we need to **add a generic function to the forward run process** that does the swap from time to datetime.  Its stored in a stand alone python script called \"helpers.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# this simply adds that helper function to the forward run process.  The None arg says\n",
    "# dont actually add a call to this function yet\n",
    "pf.add_py_function(\"helpers.py\", \"replace_time_with_datetime(csv_file)\", is_pre_cmd=None)\n",
    "\n",
    "import helpers\n",
    "# process the sfr file\n",
    "out_file,df = helpers.replace_time_with_datetime(os.path.join(template_ws, \"sfr.csv\"))\n",
    "out_file = os.path.split(out_file)[-1]\n",
    "pf.post_py_cmds.append(\"replace_time_with_datetime('sfr.csv')\")  # Add to forward run file\n",
    "pf.add_observations(\n",
    "    out_file, \n",
    "    insfile=out_file+\".ins\", \n",
    "    index_cols=\"datetime\", \n",
    "    use_cols=list(df.columns.values),\n",
    "    prefix=\"sfr\", \n",
    "    ofile_sep=\",\"\n",
    ")\n",
    "\n",
    "# process the heads file\n",
    "out_file,df = helpers.replace_time_with_datetime(os.path.join(template_ws, \"heads.csv\"))\n",
    "out_file = os.path.split(out_file)[-1]\n",
    "pf.post_py_cmds.append(\"replace_time_with_datetime('heads.csv')\")\n",
    "pf.add_observations(\n",
    "    out_file, \n",
    "    insfile=out_file+\".ins\", \n",
    "    index_cols=\"datetime\", \n",
    "    use_cols=list(df.columns.values),\n",
    "    prefix=\"hds\", \n",
    "    ofile_sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the geostruct object for grid-scale parameters\n",
    "grid_v = pyemu.geostats.ExpVario(contribution=1.0,a=500)\n",
    "grid_gs = pyemu.geostats.GeoStruct(variograms=grid_v)\n",
    "\n",
    "# the geostruct object for pilot-point-scale parameters\n",
    "pp_v = pyemu.geostats.ExpVario(contribution=1.0, a=2000)\n",
    "pp_gs = pyemu.geostats.GeoStruct(variograms=pp_v)\n",
    "\n",
    "# the geostruct for recharge grid-scale parameters\n",
    "rch_v = pyemu.geostats.ExpVario(contribution=1.0, a=1000)\n",
    "rch_gs = pyemu.geostats.GeoStruct(variograms=rch_v)\n",
    "\n",
    "# the geostruct for temporal correlation\n",
    "temporal_v = pyemu.geostats.ExpVario(contribution=1.0,a=60)\n",
    "temporal_gs = pyemu.geostats.GeoStruct(variograms=temporal_v)\n",
    "\n",
    "# import flopy as part of the forward run process\n",
    "pf.extra_py_imports.append('flopy')\n",
    "\n",
    "# use the idomain array for masking parameter locations\n",
    "ib = m.dis.idomain[0].array\n",
    "\n",
    "# define a dict that contains file name tags and lower/upper bound information\n",
    "tags = {\"npf_k_\":[0.1,10.],\"npf_k33_\":[.1,10],\"sto_ss\":[.1,10],\n",
    "        \"sto_sy\":[.9,1.1],\"rch_recharge\":[.5,1.5]}\n",
    "dts = pd.to_datetime(\"1-1-2018\") + \\\n",
    "      pd.to_timedelta(np.cumsum(sim.tdis.perioddata.array[\"perlen\"]),unit=\"d\")\n",
    "\n",
    "# loop over each tag, bound info pair\n",
    "for tag,bnd in tags.items():\n",
    "    lb,ub = bnd[0],bnd[1]\n",
    "    # find all array based files that have the tag in the name\n",
    "    arr_files = [f for f in os.listdir(template_ws) if tag in f \n",
    "\t\t\t\t and f.endswith(\".txt\")]\n",
    "\n",
    "    if len(arr_files) == 0:\n",
    "        print(\"warning: no array files found for \",tag)\n",
    "        continue\n",
    "    \n",
    "    # make sure each array file in nrow X ncol dimensions (not wrapped, sigh)\n",
    "    for arr_file in arr_files:\n",
    "        arr = np.loadtxt(os.path.join(template_ws,arr_file)).reshape(ib.shape)\n",
    "        np.savetxt(os.path.join(template_ws,arr_file),arr,fmt=\"%15.6E\")\n",
    "    \n",
    "    # if this is the recharge tag\n",
    "    if \"rch\" in tag:\n",
    "        # add one set of grid-scale parameters for all files\n",
    "        pf.add_parameters(\n",
    "            filenames=arr_files, \n",
    "            par_type=\"grid\", \n",
    "            par_name_base=\"rch_gr\",\n",
    "            pargp=\"rch_gr\", \n",
    "            zone_array=ib, \n",
    "            upper_bound=ub, \n",
    "            lower_bound=lb,\n",
    "            geostruct=rch_gs\n",
    "        )\n",
    "\n",
    "        # add one constant parameter for each array, and \n",
    "        # assign it a datetime so we can work out the \n",
    "        # temporal correlation\n",
    "        for arr_file in arr_files:\n",
    "            kper = int(arr_file.split('.')[1].split('_')[-1]) - 1\n",
    "            pf.add_parameters(\n",
    "                filenames=arr_file,\n",
    "                par_type=\"constant\",\n",
    "                par_name_base=arr_file.split('.')[1]+\"_cn\",\n",
    "                pargp=\"rch_const\",\n",
    "                zone_array=ib,\n",
    "                upper_bound=ub,\n",
    "                lower_bound=lb,\n",
    "                geostruct=temporal_gs,\n",
    "                datetime=dts[kper]\n",
    "            )\n",
    "    # otherwise...\n",
    "    else:\n",
    "        # for each array add both grid-scale and pilot-point scale parameters\n",
    "        for arr_file in arr_files:\n",
    "            pf.add_parameters(\n",
    "                filenames=arr_file,\n",
    "                par_type=\"grid\",\n",
    "                par_name_base=arr_file.split('.')[1]+\"_gr\",\n",
    "                pargp=arr_file.split('.')[1]+\"_gr\",\n",
    "                zone_array=ib,\n",
    "                upper_bound=ub,\n",
    "                lower_bound=lb,\n",
    "                geostruct=grid_gs\n",
    "            )\n",
    "            pf.add_parameters(\n",
    "                filenames=arr_file, \n",
    "                par_type=\"pilotpoints\",\n",
    "                par_name_base=arr_file.split('.')[1]+\"_pp\",\n",
    "                pargp=arr_file.split('.')[1]+\"_pp\",\n",
    "                zone_array=ib,\n",
    "                upper_bound=ub,\n",
    "                lower_bound=lb,\n",
    "                pp_space=int(5 * redis_fac),\n",
    "                geostruct=pp_gs\n",
    "            )\n",
    "\n",
    "\n",
    "# get all the list-type files associated with the wel package\n",
    "list_files = [f for f in os.listdir(tmp_model_ws) if \n",
    "\t\t\t  \"freyberg6.wel_stress_period_data_\" \n",
    "              in f and f.endswith(\".txt\")]\n",
    "# for each wel-package list-type file \n",
    "for list_file in list_files:\n",
    "    kper = int(list_file.split(\".\")[1].split('_')[-1]) - 1\n",
    "    # add spatially constant, but temporally correlated parameter\n",
    "    pf.add_parameters(\n",
    "        filenames=list_file,\n",
    "        par_type=\"constant\",\n",
    "        par_name_base=\"twel_mlt_{0}\".format(kper),\n",
    "        pargp=\"twel_mlt\".format(kper),\n",
    "        index_cols=[0,1,2],\n",
    "        use_cols=[3],\n",
    "        upper_bound=1.5,\n",
    "        lower_bound=0.5, \n",
    "        datetime=dts[kper], \n",
    "        geostruct=temporal_gs\n",
    "    )\n",
    "\n",
    "    # add temporally indep, but spatially correlated grid-scale \n",
    "    # parameters, one per well\n",
    "    pf.add_parameters(\n",
    "        filenames=list_file, \n",
    "        par_type=\"grid\", \n",
    "        par_name_base=\"wel_grid_{0}\".format(kper),\n",
    "        pargp=\"wel_{0}\".format(kper), \n",
    "        index_cols=[0, 1, 2], \n",
    "        use_cols=[3],\n",
    "        upper_bound=1.5, \n",
    "        lower_bound=0.5\n",
    "    )\n",
    "\n",
    "# add grid-scale parameters for SFR reach conductance.  \n",
    "# Use layer, row, col and reach number in the \n",
    "# parameter names\n",
    "pf.add_parameters(\n",
    "    filenames=\"freyberg6.sfr_packagedata.txt\", \n",
    "    par_name_base=\"sfr_rhk\",\n",
    "    pargp=\"sfr_rhk\", \n",
    "    index_cols=[0,1,2,3], \n",
    "    use_cols=[9], \n",
    "    upper_bound=10.,\n",
    "    lower_bound=0.1,\n",
    "    par_type=\"grid\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add model run command\n",
    "pf.mod_sys_cmds.append(\"mf6\")\n",
    "\n",
    "# build pest control file\n",
    "pst = pf.build_pst('freyberg6.pst',version=2)\n",
    "\n",
    "# draw from the prior and save the ensemble in binary format\n",
    "pe = pf.draw(300, use_specsim=True)\n",
    "pe.to_binary(os.path.join(template_ws, \"prior.jcb\"))\n",
    "\n",
    "# set some algorithmic controls\n",
    "pst.control_data.noptmax = 0\n",
    "\n",
    "# write the control file\n",
    "pst.write(os.path.join(pf.new_d, \"freyberg.pst\"))\n",
    "\n",
    "# run with noptmax = 0\n",
    "pyemu.os_utils.run(\"{0} freyberg.pst\".format(\n",
    "    os.path.join(\"pestpp-ies\")), cwd=pf.new_d)\n",
    "\n",
    "# make sure it ran\n",
    "res_file = os.path.join(pf.new_d, \"freyberg.base.rei\")\n",
    "assert os.path.exists(res_file), res_file\n",
    "pst.set_res(res_file)\n",
    "print(pst.phi)\n",
    "\n",
    "# if successful, set noptmax = -1 for prior-based Monte Carlo\n",
    "pst.control_data.noptmax = -1\n",
    "\n",
    "# define what file has the prior parameter ensemble\n",
    "pst.pestpp_options[\"ies_par_en\"] = \"prior.jcb\"\n",
    "\n",
    "# write the updated pest control file\n",
    "pst.write(os.path.join(pf.new_d, \"freyberg6.pst\"),version=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
